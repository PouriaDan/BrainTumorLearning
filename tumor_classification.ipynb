{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrunners\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EpochRunner\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy, precision, recall, f1_score\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TumorClassificationModel\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:991\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1087\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1186\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import os.path as osp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from dataset import TumorClassificationDataset\n",
    "from visualization import TrainingPlotter, set_ax_borders, plot_cm, plot_class_distribution\n",
    "from utils import Logger, get_lr_scheduler, get_current_lr, save_weights, load_weights\n",
    "from runners import EpochRunner\n",
    "from metrics import accuracy, precision, recall, f1_score\n",
    "from model import TumorClassificationModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"Data/Classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    data = []\n",
    "    target = []\n",
    "    sub_dirs = os.listdir(data_path)\n",
    "    for sub_dir in sub_dirs:\n",
    "        img_pths = glob.glob(osp.join(data_path, sub_dir, \"*.jpg\"))\n",
    "        data.extend(img_pths)\n",
    "        target.extend([sub_dir]*len(img_pths))\n",
    "    assert len(data)==len(target)\n",
    "    return data, target\n",
    "\n",
    "data_X, data_y = read_data(datapath)\n",
    "print(f\"A total of {len(data_X)} accross {len(np.unique(data_y))} are available\")\n",
    "train_size = .7\n",
    "valid_size = .1\n",
    "test_size = .2\n",
    "train_X, val_test_X, train_y, val_test_y = train_test_split(data_X, data_y, train_size=train_size, stratify=data_y, random_state=42)\n",
    "test_X, val_X, test_y, val_y = train_test_split(val_test_X, val_test_y, train_size=test_size/(1-train_size), stratify=val_test_y, random_state=42)\n",
    "print(f\"A total of {len(train_X)} accross {len(np.unique(data_y))} are available for training ({train_size*100}% of Data)\")\n",
    "print(f\"A total of {len(val_X)} accross {len(np.unique(data_y))} are available for validation ({valid_size*100}% of Data)\")\n",
    "print(f\"A total of {len(test_X)} accross {len(np.unique(data_y))} are available for testing ({test_size*100}% of Data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul, train_counts = np.unique(train_y, return_counts=True)\n",
    "ul, valid_counts = np.unique(val_y, return_counts=True)\n",
    "ul, test_counts = np.unique(test_y, return_counts=True)\n",
    "\n",
    "count_df = pd.DataFrame(index=ul, data={'Train': train_counts, 'Val': valid_counts, 'Test': test_counts})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_class_distribution(train_y, val_y, test_y, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "sample_ds = TumorClassificationDataset(data_X, data_y, transform_pipeline)\n",
    "classes = sample_ds.get_class_names()\n",
    "class_samples = {}\n",
    "for class_ in classes:\n",
    "    class_samples[class_] = [sample_ds.get_class_samples(class_,i)[0] for i in np.random.randint(0,10000,4)]\n",
    "    \n",
    "fig, axes = plt.subplots(ncols=4, nrows=4)\n",
    "fig.set_size_inches(9,9)\n",
    "for n_col, class_ in enumerate(class_samples.keys()):\n",
    "    axes[0, n_col].set_title(class_)\n",
    "    for n_row, img in enumerate(class_samples[class_]):\n",
    "        axes[n_row,n_col].imshow(img[0], cmap='gray')\n",
    "        axes[n_row,n_col].set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LR = 1e-3\n",
    "WEIGHTS = None\n",
    "now = datetime.datetime.now()\n",
    "WORK_DIR = \"./experiments/classification/exp_\" + now.strftime(\"%m-%d-%y_%H-%M\")\n",
    "EPOCHS = 30\n",
    "if os.path.exists(osp.join(WORK_DIR, 'train_log.txt')):\n",
    "    os.remove(osp.join(WORK_DIR, 'train_log.txt'))\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "train_dataset = TumorClassificationDataset(train_X, train_y, transform_pipeline)\n",
    "val_dataset   = TumorClassificationDataset(val_X,   val_y,   transform_pipeline)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "model = TumorClassificationModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=BASE_LR)\n",
    "iterations_per_epoch = len(train_dataloader)\n",
    "scheduler = get_lr_scheduler(optimizer, 'CosineAnnealingLRwithWarmupFixed', EPOCHS, iterations_per_epoch, {'min_lr': BASE_LR*0.1, 'start_factor': 0.1})\n",
    "\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN=True\n",
    "if TRAIN: \n",
    "    plotter = TrainingPlotter(\"accuracy\")\n",
    "\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    train_logger = Logger('train', osp.join(WORK_DIR, 'train_log.txt'))\n",
    "\n",
    "    train_logger.log_message(f\"Training parameters:\")\n",
    "    train_logger.log_message(f\"Base learning rate: {BASE_LR}\")\n",
    "    train_logger.log_message(f\"Number of parameters: {num_params}\")\n",
    "    train_logger.log_message(f\"Device: {DEVICE}\")\n",
    "\n",
    "    epoch_runner = EpochRunner(model, DEVICE, optimizer, criterion, scheduler, [accuracy])\n",
    "    train_logger.log_message(f\"Training for {EPOCHS} epochs\")\n",
    "    best_val_acc = -1\n",
    "\n",
    "    try:\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_metrics, train_loss = epoch_runner.run_epoch('train', epoch, train_dataloader)\n",
    "            current_lr = get_current_lr(optimizer)[0]\n",
    "            train_logger.log_training(epoch + 1, train_loss, train_metrics, current_lr)\n",
    "\n",
    "            val_metrics, val_loss, _, _, _ = epoch_runner.run_epoch('validate', epoch, val_dataloader)\n",
    "            train_logger.log_validation(epoch + 1, val_loss, val_metrics)\n",
    "\n",
    "            plotter.update(epoch, train_metrics['accuracy'], val_metrics['accuracy'], train_loss, val_loss)\n",
    "\n",
    "            val_acc = val_metrics['accuracy']\n",
    "            save_weights(model, f\"epoch_{epoch + 1:03d}.pth\", WORK_DIR)\n",
    "            if val_acc > best_val_acc:\n",
    "                best_epoch_name_str = f\"best_val_results_epoch_{epoch + 1:03d}_acc_{val_acc:.2f}.pth\"\n",
    "                save_weights(model, best_epoch_name_str, WORK_DIR, \"best_val_results\")\n",
    "                best_val_acc = val_acc\n",
    "    except KeyboardInterrupt:\n",
    "        train_logger.log_message(f\"Training interrupted by user\")\n",
    "        \n",
    "    train_logger.log_message(f\"Training completed\")\n",
    "    train_logger.log_message(f\"Best validation accuracy: {best_val_acc}\")\n",
    "    train_logger.close()\n",
    "\n",
    "    plotter.save_plot(osp.join(WORK_DIR, 'training_plot.png'))\n",
    "    plotter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "test_dataset = TumorClassificationDataset(test_X, test_y, transform_pipeline)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "if os.path.exists(osp.join(WORK_DIR, 'test_log.txt')):\n",
    "    os.remove(osp.join(WORK_DIR, 'test_log.txt'))\n",
    "    \n",
    "best_weights = glob.glob(osp.join(WORK_DIR, \"best_val_*.pth\"))[0]\n",
    "load_weights(model, best_weights)\n",
    "\n",
    "epoch_runner = EpochRunner(model, DEVICE, optimizer, criterion, None, [accuracy, precision, recall])\n",
    "\n",
    "test_logger = Logger('test', osp.join(WORK_DIR, 'test_log.txt'))\n",
    "test_logger.log_message(f\"Testing with best weights from {best_weights}\")\n",
    "test_logger.log_message(f\"Testing\")\n",
    "test_metrics, test_loss, test_preds, test_gts, test_feats = epoch_runner.run_epoch('test', 0, test_dataloader)\n",
    "test_logger.log_test(1, test_loss, test_metrics)\n",
    "\n",
    "test_logger.log_message(f\"Testing completed\")\n",
    "metrics_str = \", \".join([f\"{k}: {v:.4f}\" for k, v in test_metrics.items()])\n",
    "test_logger.log_message(f\"Test metrics: {metrics_str}\")\n",
    "test_logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.lines as mlines\n",
    "import argparse\n",
    "import os.path as osp\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "\n",
    "def plot_cm(gt_labels, pred_labels, idx_to_class, ax=None):\n",
    "    acc = accuracy(gt_labels, pred_labels)\n",
    "    pred_labels = np.argmax(pred_labels, axis=1)\n",
    "    labels = list(idx_to_class.values())\n",
    "    cm = confusion_matrix(gt_labels, pred_labels)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cm, annot=True, fmt=\".1%\", ax=ax,\n",
    "                cmap=\"Blues\", vmin=0, vmax=1,\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_title(f\"Accuracy: {acc*100:.2f}%\")\n",
    "    ax.set_aspect('equal')\n",
    "    return cm\n",
    "\n",
    "def compress_latents(latents, compressor_method=PCA):\n",
    "    compressor = compressor_method(n_components=2)\n",
    "    pred_feats = compressor.fit_transform(latents)\n",
    "    return pred_feats\n",
    "\n",
    "gt_labels = np.array(test_gts)\n",
    "pred_labels = np.array(test_preds)\n",
    "pred_feats = np.array(test_feats).reshape(-1,128*7*7)\n",
    "latents = compress_latents(pred_feats, compressor_method=TSNE)\n",
    "    \n",
    "COLORS = ['blue', 'orange', 'green', 'red', 'purple']\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2)\n",
    "fig.set_size_inches(16,5)\n",
    "plot_cm(gt_labels, pred_labels, test_dataset.idx_to_class, axes[0])\n",
    "axes[1].scatter(latents[:,0], latents[:,1], \n",
    "                c = gt_labels, cmap=matplotlib.colors.ListedColormap(COLORS), s=10, marker='.')\n",
    "handles = []\n",
    "for i, label in enumerate(test_dataset.get_class_names()):\n",
    "    l = mlines.Line2D([], [], color=COLORS[i], marker='.', linestyle='None',\n",
    "                            markersize=10, label=f\"{label}\")\n",
    "    handles.append(l)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.06),\n",
    "           fancybox=True, shadow=False, ncol=6, handles=handles, frameon=False)\n",
    "set_ax_borders(axes[1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genomtechlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
